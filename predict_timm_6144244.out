hello
importing modules
imported dataset_1
imported torch
imported pytorch_lightning
imported pytorch_lightning callbacks
imported timm
hello
importing modules
imported dataset_1
imported torch
imported pytorch_lightning
imported pytorch_lightning callbacks
imported timm
starting
in_feats 1536
no pretrained backbone loaded
backbone modified head  ClassifierHead(
  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())
  (drop): Dropout(p=0.0, inplace=False)
  (fc): Identity()
  (flatten): Identity()
)
Timm data_cfg {'input_size': (3, 384, 384), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 1.0, 'crop_mode': 'center'}
using norm_std (0.229, 0.224, 0.225)
using norm_mean (0.485, 0.456, 0.406)
loading model from checkpoint 5usybm65
loaded 300 test examples
predicting ['C1/3-1-2-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/3-1-2-submit-73549.mp4']
sequences torch.Size([102, 1, 3, 384, 384])
predicting ['C1/3-1-2-submit-74734.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/3-1-2-submit-74766.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/3-1-2-submit-75090.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-74734.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-74766.mp4']
sequences torch.Size([147, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-75090.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-73549.mp4']
sequences torch.Size([102, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-74734.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-74766.mp4']
sequences torch.Size([111, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-75090.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-74734.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-74766.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-75090.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-74734.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-74766.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-75090.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-74734.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-74766.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-75090.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-73549.mp4']
sequences torch.Size([152, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-74734.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-74766.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-75090.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-00000.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-74734.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-74766.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-75090.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-73549.mp4']
sequences torch.Size([127, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-74734.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-74766.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-75090.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-73549.mp4']
sequences torch.Size([152, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-74734.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-74766.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-75090.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-73549.mp4']
sequences torch.Size([152, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-74734.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-74766.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-75090.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-73549.mp4']
sequences torch.Size([102, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-74734.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-74766.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-75090.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82882.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-83063.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-00000.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82495.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82501.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82882.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82910.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82999.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-83063.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-83485.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-83619.mp4']
sequences torch.Size([146, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82882.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-83063.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82882.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-83063.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82882.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-83063.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82495.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82501.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82882.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82910.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82999.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-83063.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-83485.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-83619.mp4']
sequences torch.Size([146, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-00000.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82495.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82501.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82882.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82910.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82999.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-83063.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-83485.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-83619.mp4']
sequences torch.Size([170, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82882.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-83063.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82495.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82501.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82882.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82910.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82999.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-83063.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-83485.mp4']
sequences torch.Size([112, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-83619.mp4']
sequences torch.Size([98, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82495.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82501.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82882.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82910.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82999.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-83063.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-83485.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-83619.mp4']
sequences torch.Size([98, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82495.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82501.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82882.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82910.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82999.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-83063.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-83485.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-83619.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82495.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82501.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82882.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82910.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82999.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-83063.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-83485.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-83619.mp4']
sequences torch.Size([146, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-91740.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-92068.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-92069.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-92582.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93056.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93059.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93062.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93065.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93110.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93169.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93170.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-91740.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-92068.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-92069.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-92582.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93056.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93059.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93062.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93065.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93110.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93169.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93170.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-91740.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-92068.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-92069.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-92582.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93056.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93059.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93062.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93065.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93110.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93169.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93170.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-91740.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-92068.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-92069.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-92582.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93056.mp4']
sequences torch.Size([208, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93059.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93062.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93065.mp4']
sequences torch.Size([208, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93110.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93169.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93170.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-91740.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-92068.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-92069.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-92582.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93056.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93059.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93062.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93065.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93110.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93169.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93170.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-91740.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-92068.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-92069.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-92582.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93056.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93059.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93062.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93065.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93110.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93169.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93170.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-91740.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-92068.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-92069.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-92582.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93056.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93059.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93062.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93065.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93110.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93169.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93170.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-91740.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-92068.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-92069.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-92582.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93056.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93059.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93062.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93065.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93110.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93169.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93170.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-91740.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-92068.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-92069.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-92582.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93056.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93059.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93062.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93065.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93110.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93169.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93170.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-91740.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-92068.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-92069.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-92582.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93056.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93059.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93062.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93065.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93110.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93169.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93170.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-91740.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-92068.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-92069.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-92582.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93056.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93059.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93062.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93065.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93110.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
Video directory: ../dataset/C2/13-2-4-submit-82882.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83485.mp4 has 719 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92068.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93059.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93169.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-74734.mp4 has 604 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-00000.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82910.mp4 has 724 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92069.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93062.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93170.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-74766.mp4 has 600 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82495.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82999.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92582.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93065.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-00000.mp4 has 600 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-75090.mp4 has 601 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82501.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83063.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-91740.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93056.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93110.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-74766.mp4 has 600 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82495.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82999.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92582.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93065.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82882.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83485.mp4 has 719 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92068.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93059.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93169.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-74734.mp4 has 604 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-00000.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82910.mp4 has 724 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92069.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93062.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93170.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-00000.mp4 has 600 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-75090.mp4 has 601 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82501.mp4 has 722 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83063.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-91740.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93056.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93110.mp4 has 720 frames which is more than 250 frames
predicting ['C3/8-1-10-submit-93169.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93170.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-91740.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-92068.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-92069.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-92582.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93056.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93059.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93062.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93065.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93110.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93169.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93170.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicted 300 labels for ['C3/8-2-10-submit-93170.mp4']
all_test_gt: [4.199999809265137, 4.0, 2.799999952316284, 1.600000023841858, 2.200000047683716, 4.0, 2.799999952316284, 2.200000047683716, 1.600000023841858, 2.4000000953674316, 2.799999952316284, 3.0, 3.200000047683716, 1.600000023841858, 2.200000047683716, 4.199999809265137, 3.5999999046325684, 3.0, 1.7999999523162842, 2.5999999046325684, 3.799999952316284, 3.799999952316284, 3.0, 2.200000047683716, 2.5999999046325684, 3.5999999046325684, 4.0, 3.5999999046325684, 2.0, 2.200000047683716, 4.199999809265137, 2.200000047683716, 3.4000000953674316, 2.0, 2.4000000953674316, 4.199999809265137, 3.200000047683716, 3.200000047683716, 1.600000023841858, 3.4000000953674316, 2.5999999046325684, 3.799999952316284, 2.799999952316284, 2.0, 2.799999952316284, 2.799999952316284, 3.799999952316284, 3.200000047683716, 2.0, 3.200000047683716, 2.200000047683716, 3.200000047683716, 3.0, 1.7999999523162842, 2.4000000953674316, 2.5999999046325684, 3.4000000953674316, 3.0, 2.0, 3.0, 4.199999809265137, 3.200000047683716, 3.5999999046325684, 4.0, 3.799999952316284, 3.200000047683716, 2.4000000953674316, 1.600000023841858, 3.799999952316284, 4.0, 3.200000047683716, 4.199999809265137, 4.199999809265137, 4.199999809265137, 3.0, 2.200000047683716, 1.399999976158142, 3.5999999046325684, 3.200000047683716, 3.5999999046325684, 4.199999809265137, 3.5999999046325684, 4.0, 3.200000047683716, 3.5999999046325684, 2.0, 3.799999952316284, 3.5999999046325684, 3.0, 4.400000095367432, 3.799999952316284, 3.5999999046325684, 3.200000047683716, 2.5999999046325684, 2.0, 3.5999999046325684, 3.0, 3.4000000953674316, 4.0, 3.4000000953674316, 3.0, 2.4000000953674316, 2.200000047683716, 1.7999999523162842, 3.799999952316284, 3.4000000953674316, 3.0, 4.199999809265137, 3.200000047683716, 3.200000047683716, 2.799999952316284, 2.5999999046325684, 2.4000000953674316, 3.200000047683716, 3.799999952316284, 3.200000047683716, 3.5999999046325684, 4.0, 3.4000000953674316, 2.0, 2.4000000953674316, 1.600000023841858, 3.5999999046325684, 4.0, 2.4000000953674316, 3.799999952316284, 4.199999809265137, 3.5999999046325684, 2.200000047683716, 2.4000000953674316, 1.7999999523162842, 3.0, 3.5999999046325684, 2.799999952316284, 3.4000000953674316, 3.4000000953674316, 3.5999999046325684, 1.7999999523162842, 1.600000023841858, 1.399999976158142, 3.5999999046325684, 4.199999809265137, 3.0, 3.799999952316284, 4.199999809265137, 3.5999999046325684, 2.5999999046325684, 1.7999999523162842, 1.7999999523162842, 2.799999952316284, 4.0, 3.5999999046325684, 4.199999809265137, 4.199999809265137, 4.0, 3.4000000953674316, 3.4000000953674316, 1.7999999523162842, 3.0, 3.5999999046325684, 4.199999809265137, 4.199999809265137, 4.199999809265137, 3.799999952316284, 3.0, 3.4000000953674316, 1.7999999523162842, 3.200000047683716, 3.4000000953674316, 3.4000000953674316, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.5999999046325684, 2.4000000953674316, 2.4000000953674316, 4.0, 3.799999952316284, 3.200000047683716, 3.4000000953674316, 3.799999952316284, 4.0, 4.0, 4.199999809265137, 3.799999952316284, 2.4000000953674316, 3.4000000953674316, 3.799999952316284, 4.0, 4.0, 3.4000000953674316, 3.799999952316284, 4.0, 3.799999952316284, 3.799999952316284, 3.0, 2.4000000953674316, 2.4000000953674316, 3.4000000953674316, 4.0, 3.799999952316284, 3.5999999046325684, 3.799999952316284, 3.799999952316284, 3.5999999046325684, 3.5999999046325684, 3.0, 3.0, 2.799999952316284, 3.4000000953674316, 3.799999952316284, 3.5999999046325684, 3.0, 3.200000047683716, 3.5999999046325684, 3.200000047683716, 3.4000000953674316, 3.799999952316284, 2.5999999046325684, 3.0, 3.4000000953674316, 4.0, 3.4000000953674316, 3.200000047683716, 3.4000000953674316, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.799999952316284, 3.200000047683716, 2.799999952316284, 4.0, 4.0, 4.199999809265137, 4.199999809265137, 3.5999999046325684, 2.200000047683716, 2.4000000953674316, 3.200000047683716, 3.200000047683716, 3.4000000953674316, 2.799999952316284, 3.5999999046325684, 4.199999809265137, 3.799999952316284, 3.4000000953674316, 4.0, 2.200000047683716, 2.200000047683716, 3.5999999046325684, 4.0, 3.4000000953674316, 2.5999999046325684, 3.799999952316284, 3.799999952316284, 3.5999999046325684, 3.799999952316284, 2.799999952316284, 3.200000047683716, 3.4000000953674316, 3.799999952316284, 4.199999809265137, 4.0, 3.200000047683716, 4.0, 4.199999809265137, 4.199999809265137, 4.199999809265137, 3.200000047683716, 2.200000047683716, 2.200000047683716, 3.200000047683716, 4.199999809265137, 4.199999809265137, 3.5999999046325684, 4.199999809265137, 4.199999809265137, 4.199999809265137, 4.199999809265137, 3.200000047683716, 2.5999999046325684, 2.799999952316284, 3.200000047683716, 3.799999952316284, 3.200000047683716, 3.4000000953674316, 4.199999809265137, 4.0, 4.199999809265137, 4.0, 2.799999952316284, 3.4000000953674316, 3.4000000953674316]
saved 300 predictions to ./predictions/5usybm65/-1/Test1_preds.txt
loaded 280 test examples
predicting ['C1/1-1-3-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/1-2-2-submit-73479.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/2-1-4-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/2-2-1-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/5-1-1-submit-73479.mp4']
sequences torch.Size([101, 1, 3, 384, 384])
predicting ['C1/5-2-9-submit-73479.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/6-1-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/6-2-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/7-1-1-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/7-2-10-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/9-1-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/9-2-5-submit-73479.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C1/10-1-1-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/10-2-6-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/12-1-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/12-2-1-submit-73479.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C1/14-1-1-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/14-2-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/16-1-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/16-2-3-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/18-1-1-submit-73479.mp4']
sequences torch.Size([126, 1, 3, 384, 384])
predicting ['C1/18-2-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/20-1-2-submit-73479.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C1/20-2-1-submit-73479.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C1/21-1-1-submit-73479.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C1/21-2-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/22-1-1-submit-73479.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C1/22-2-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/10-1-4-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/10-1-4-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/10-1-4-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/10-1-4-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/10-2-3-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/10-2-3-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/10-2-3-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/10-2-3-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/1-1-4-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/1-1-4-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/1-1-4-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/1-1-4-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/12-1-9-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/12-1-9-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/12-1-9-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/12-1-9-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/12-2-4-submit-82508.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/12-2-4-submit-82511.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/12-2-4-submit-83496.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/12-2-4-submit-83609.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/1-2-3-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/1-2-3-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/1-2-3-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/1-2-3-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/14-1-2-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/14-1-2-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/14-1-2-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/14-1-2-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/14-2-4-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/14-2-4-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/14-2-4-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/14-2-4-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/16-1-4-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/16-1-4-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/16-1-4-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/16-1-4-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/16-2-5-submit-82508.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/16-2-5-submit-82511.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/16-2-5-submit-83496.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/16-2-5-submit-83609.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/18-1-3-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/18-1-3-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/18-1-3-submit-83496.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/18-1-3-submit-83609.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/18-2-4-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/18-2-4-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/18-2-4-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/18-2-4-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/20-1-3-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/20-1-3-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/20-1-3-submit-83496.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/20-1-3-submit-83609.mp4']
sequences torch.Size([151, 1, 3, 384, 384])
predicting ['C2/20-2-3-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/20-2-3-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/20-2-3-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/20-2-3-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/21-1-2-submit-82508.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/21-1-2-submit-82511.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C2/21-1-2-submit-83496.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/21-1-2-submit-83609.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/2-1-1-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/2-1-1-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/2-1-1-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/2-1-1-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/21-2-4-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/21-2-4-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/21-2-4-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/21-2-4-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/22-1-2-submit-82508.mp4']
sequences torch.Size([240, 1, 3, 384, 384])
predicting ['C2/22-1-2-submit-82511.mp4']
sequences torch.Size([239, 1, 3, 384, 384])
predicting ['C2/22-1-2-submit-83496.mp4']
sequences torch.Size([240, 1, 3, 384, 384])
predicting ['C2/22-1-2-submit-83609.mp4']
sequences torch.Size([240, 1, 3, 384, 384])
predicting ['C2/22-2-3-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/22-2-3-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/22-2-3-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/22-2-3-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/2-2-4-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/2-2-4-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/2-2-4-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/2-2-4-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/5-1-8-submit-82508.mp4']
sequences torch.Size([100, 1, 3, 384, 384])
predicting ['C2/5-1-8-submit-82511.mp4']
sequences torch.Size([99, 1, 3, 384, 384])
predicting ['C2/5-1-8-submit-83496.mp4']
sequences torch.Size([101, 1, 3, 384, 384])
predicting ['C2/5-1-8-submit-83609.mp4']
sequences torch.Size([101, 1, 3, 384, 384])
predicting ['C2/5-2-2-submit-82508.mp4']
sequences torch.Size([90, 1, 3, 384, 384])
predicting ['C2/5-2-2-submit-82511.mp4']
sequences torch.Size([89, 1, 3, 384, 384])
predicting ['C2/5-2-2-submit-83496.mp4']
sequences torch.Size([90, 1, 3, 384, 384])
predicting ['C2/5-2-2-submit-83609.mp4']
sequences torch.Size([90, 1, 3, 384, 384])
predicting ['C2/6-1-6-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/6-1-6-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/6-1-6-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/6-1-6-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/6-2-7-submit-82508.mp4']
sequences torch.Size([113, 1, 3, 384, 384])
predicting ['C2/6-2-7-submit-82511.mp4']
sequences torch.Size([112, 1, 3, 384, 384])
predicting ['C2/6-2-7-submit-83496.mp4']
sequences torch.Size([113, 1, 3, 384, 384])
predicting ['C2/6-2-7-submit-83609.mp4']
sequences torch.Size([113, 1, 3, 384, 384])
predicting ['C2/7-1-5-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/7-1-5-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/7-1-5-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/7-1-5-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/7-2-3-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/7-2-3-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/7-2-3-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/7-2-3-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-1-4-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-1-4-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/9-1-4-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-1-4-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-2-2-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-2-2-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/9-2-2-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/9-2-2-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/10-1-8-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-1-8-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-1-8-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-1-8-submit-93014.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/10-1-8-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/10-2-2-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-2-2-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-2-2-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/10-2-2-submit-93014.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/10-2-2-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/1-1-6-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/1-1-6-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/1-1-6-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/1-1-6-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/1-1-6-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/12-1-15-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/12-1-15-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/12-1-15-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/12-1-15-submit-93014.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/12-1-15-submit-93060.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/12-2-12-submit-00000.mp4']
sequences torch.Size([121, 1, 3, 384, 384])
predicting ['C3/12-2-12-submit-92147.mp4']
sequences torch.Size([121, 1, 3, 384, 384])
predicting ['C3/12-2-12-submit-92584.mp4']
sequences torch.Size([122, 1, 3, 384, 384])
predicting ['C3/12-2-12-submit-93014.mp4']
sequences torch.Size([121, 1, 3, 384, 384])
predicting ['C3/12-2-12-submit-93060.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/1-2-5-submit-00000.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/1-2-5-submit-92147.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/1-2-5-submit-92584.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/1-2-5-submit-93014.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C3/1-2-5-submit-93060.mp4']
sequences torch.Size([208, 1, 3, 384, 384])
predicting ['C3/14-1-6-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-1-6-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-1-6-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-1-6-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/14-1-6-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/14-2-6-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-2-6-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-2-6-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-2-6-submit-93014.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/14-2-6-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/16-1-9-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/16-1-9-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/16-1-9-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/16-1-9-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/16-1-9-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/16-2-10-submit-00000.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/16-2-10-submit-92147.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/16-2-10-submit-92584.mp4']
sequences torch.Size([96, 1, 3, 384, 384])
predicting ['C3/16-2-10-submit-93014.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/16-2-10-submit-93060.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/18-1-6-submit-00000.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
Video directory: ../dataset/C2/16-2-5-submit-82508.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-93014.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-83609.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-82511.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-00000.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-93060.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-83496.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-92147.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-82508.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-93014.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-82511.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-00000.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-93060.mp4 has 269 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-83496.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C3/16-2-10-submit-92147.mp4 has 270 frames which is more than 250 frames
Video directory: ../dataset/C2/16-2-5-submit-83609.mp4 has 270 frames which is more than 250 frames
predicting ['C3/18-1-6-submit-92147.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/18-1-6-submit-92584.mp4']
sequences torch.Size([126, 1, 3, 384, 384])
predicting ['C3/18-1-6-submit-93014.mp4']
sequences torch.Size([124, 1, 3, 384, 384])
predicting ['C3/18-1-6-submit-93060.mp4']
sequences torch.Size([123, 1, 3, 384, 384])
predicting ['C3/18-2-7-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/18-2-7-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/18-2-7-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/18-2-7-submit-93014.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/18-2-7-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/20-1-8-submit-00000.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/20-1-8-submit-92147.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/20-1-8-submit-92584.mp4']
sequences torch.Size([126, 1, 3, 384, 384])
predicting ['C3/20-1-8-submit-93014.mp4']
sequences torch.Size([124, 1, 3, 384, 384])
predicting ['C3/20-1-8-submit-93060.mp4']
sequences torch.Size([123, 1, 3, 384, 384])
predicting ['C3/20-2-8-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/20-2-8-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/20-2-8-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/20-2-8-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/20-2-8-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/21-1-3-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/21-1-3-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/21-1-3-submit-92584.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/21-1-3-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/21-1-3-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/21-2-7-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/21-2-7-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/21-2-7-submit-92584.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/21-2-7-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/21-2-7-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/2-1-7-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-1-7-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-1-7-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-1-7-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/2-1-7-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/2-2-11-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-2-11-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-2-11-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/2-2-11-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/2-2-11-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/22-1-4-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-1-4-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-1-4-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-1-4-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/22-1-4-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/22-2-1-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-2-1-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-2-1-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/22-2-1-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/22-2-1-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/5-1-17-submit-00000.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/5-1-17-submit-92147.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/5-1-17-submit-92584.mp4']
sequences torch.Size([126, 1, 3, 384, 384])
predicting ['C3/5-1-17-submit-93014.mp4']
sequences torch.Size([125, 1, 3, 384, 384])
predicting ['C3/5-1-17-submit-93060.mp4']
sequences torch.Size([123, 1, 3, 384, 384])
predicting ['C3/5-2-10-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/5-2-10-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/5-2-10-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/5-2-10-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/5-2-10-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/6-1-12-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/6-1-12-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/6-1-12-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/6-1-12-submit-93014.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/6-1-12-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/6-2-11-submit-00000.mp4']
sequences torch.Size([176, 1, 3, 384, 384])
predicting ['C3/6-2-11-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/6-2-11-submit-92584.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/6-2-11-submit-93014.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/6-2-11-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/7-1-12-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/7-1-12-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/7-1-12-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/7-1-12-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/7-1-12-submit-93060.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/7-2-9-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/7-2-9-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/7-2-9-submit-92584.mp4']
sequences torch.Size([124, 1, 3, 384, 384])
predicting ['C3/7-2-9-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/7-2-9-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/9-1-10-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/9-1-10-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/9-1-10-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/9-1-10-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/9-1-10-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/9-2-8-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/9-2-8-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/9-2-8-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/9-2-8-submit-93014.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/9-2-8-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicted 280 labels for ['C3/9-2-8-submit-93060.mp4']
all_test_gt: [2.200000047683716, 2.4000000953674316, 2.5999999046325684, 2.5999999046325684, 3.0, 2.200000047683716, 3.5999999046325684, 3.0, 3.4000000953674316, 2.5999999046325684, 3.5999999046325684, 3.0, 3.0, 2.799999952316284, 2.4000000953674316, 2.0, 2.4000000953674316, 2.0, 2.5999999046325684, 2.200000047683716, 3.0, 2.4000000953674316, 3.200000047683716, 2.799999952316284, 3.0, 2.200000047683716, 3.200000047683716, 3.0, 1.7999999523162842, 4.0, 3.0, 3.0, 2.0, 4.199999809265137, 3.799999952316284, 3.4000000953674316, 1.600000023841858, 3.799999952316284, 2.200000047683716, 2.4000000953674316, 2.200000047683716, 4.0, 2.799999952316284, 3.200000047683716, 1.7999999523162842, 4.0, 3.200000047683716, 3.4000000953674316, 1.600000023841858, 4.199999809265137, 2.0, 3.200000047683716, 1.600000023841858, 3.5999999046325684, 3.5999999046325684, 3.5999999046325684, 1.600000023841858, 3.4000000953674316, 3.4000000953674316, 3.4000000953674316, 1.7999999523162842, 3.5999999046325684, 3.200000047683716, 3.4000000953674316, 1.7999999523162842, 3.5999999046325684, 3.0, 3.0, 1.600000023841858, 3.5999999046325684, 2.5999999046325684, 2.799999952316284, 1.600000023841858, 4.199999809265137, 3.0, 3.5999999046325684, 1.600000023841858, 3.200000047683716, 2.4000000953674316, 2.799999952316284, 1.600000023841858, 3.4000000953674316, 2.799999952316284, 3.0, 2.0, 3.4000000953674316, 2.5999999046325684, 1.7999999523162842, 1.7999999523162842, 3.5999999046325684, 3.200000047683716, 3.5999999046325684, 1.7999999523162842, 3.799999952316284, 2.4000000953674316, 2.4000000953674316, 2.0, 3.5999999046325684, 3.5999999046325684, 3.799999952316284, 2.200000047683716, 3.799999952316284, 3.5999999046325684, 3.4000000953674316, 1.7999999523162842, 3.4000000953674316, 2.5999999046325684, 2.799999952316284, 1.600000023841858, 3.799999952316284, 2.5999999046325684, 3.0, 1.7999999523162842, 4.199999809265137, 2.5999999046325684, 3.200000047683716, 1.7999999523162842, 4.0, 3.200000047683716, 4.0, 1.600000023841858, 3.5999999046325684, 2.200000047683716, 3.799999952316284, 1.600000023841858, 4.0, 3.200000047683716, 3.799999952316284, 2.200000047683716, 4.199999809265137, 3.0, 3.5999999046325684, 1.600000023841858, 3.799999952316284, 2.4000000953674316, 3.4000000953674316, 1.600000023841858, 3.200000047683716, 3.0, 3.5999999046325684, 4.199999809265137, 4.0, 1.7999999523162842, 4.199999809265137, 4.199999809265137, 4.0, 3.799999952316284, 1.7999999523162842, 4.0, 3.799999952316284, 4.400000095367432, 4.199999809265137, 1.7999999523162842, 4.199999809265137, 4.199999809265137, 4.0, 3.4000000953674316, 2.0, 4.0, 4.0, 4.199999809265137, 2.799999952316284, 1.7999999523162842, 4.199999809265137, 4.0, 4.400000095367432, 4.0, 2.5999999046325684, 4.199999809265137, 4.199999809265137, 4.0, 3.5999999046325684, 1.7999999523162842, 4.199999809265137, 4.199999809265137, 3.4000000953674316, 3.4000000953674316, 1.7999999523162842, 4.0, 4.0, 3.799999952316284, 3.4000000953674316, 1.600000023841858, 3.5999999046325684, 3.799999952316284, 3.799999952316284, 3.4000000953674316, 1.2000000476837158, 3.4000000953674316, 4.0, 3.5999999046325684, 3.200000047683716, 2.4000000953674316, 3.5999999046325684, 3.799999952316284, 3.799999952316284, 3.5999999046325684, 2.0, 4.199999809265137, 4.0, 3.4000000953674316, 3.5999999046325684, 1.7999999523162842, 3.799999952316284, 3.799999952316284, 3.5999999046325684, 3.5999999046325684, 1.600000023841858, 4.199999809265137, 4.199999809265137, 3.5999999046325684, 3.5999999046325684, 1.2000000476837158, 4.0, 4.0, 3.4000000953674316, 2.799999952316284, 1.600000023841858, 3.4000000953674316, 3.4000000953674316, 4.199999809265137, 3.799999952316284, 2.0, 3.799999952316284, 3.799999952316284, 4.0, 2.5999999046325684, 1.7999999523162842, 4.199999809265137, 4.199999809265137, 4.199999809265137, 4.0, 1.399999976158142, 3.799999952316284, 4.199999809265137, 4.199999809265137, 4.0, 1.600000023841858, 4.199999809265137, 4.199999809265137, 3.799999952316284, 4.0, 2.0, 4.0, 3.799999952316284, 4.0, 3.799999952316284, 2.0, 4.199999809265137, 4.199999809265137, 4.400000095367432, 3.200000047683716, 1.7999999523162842, 4.199999809265137, 4.199999809265137, 2.799999952316284, 2.799999952316284, 1.7999999523162842, 4.199999809265137, 4.400000095367432, 4.0, 3.4000000953674316, 1.7999999523162842, 3.0, 4.0, 3.799999952316284, 3.5999999046325684, 1.7999999523162842, 4.0, 4.199999809265137, 3.4000000953674316, 3.5999999046325684, 1.600000023841858, 4.0, 4.0, 4.199999809265137, 4.0, 2.200000047683716, 4.0, 3.5999999046325684]
saved 280 predictions to ./predictions/5usybm65/-1/Test2_preds.txt
loaded 120 test examples
predicting ['C1/3-1-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/3-2-5-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/4-1-1-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C1/4-2-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-1-1-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/8-2-5-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/13-1-1-submit-73479.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/13-2-2-submit-73479.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C1/15-1-2-submit-73479.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C1/15-2-1-submit-73479.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-1-1-submit-73479.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C1/19-2-2-submit-73479.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-1-3-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82508.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-82511.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-83496.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/13-2-4-submit-83609.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-1-4-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/15-2-3-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-1-2-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/19-2-1-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82508.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-82511.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-83496.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-1-4-submit-83609.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/3-2-2-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-1-4-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82508.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-82511.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-83496.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/4-2-4-submit-83609.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82508.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-82511.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-83496.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-1-6-submit-83609.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82508.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-82511.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-83496.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C2/8-2-2-submit-83609.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/13-1-4-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-00000.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-92147.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-92584.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93014.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/13-2-5-submit-93060.mp4']
sequences torch.Size([250, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93014.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicting ['C3/15-1-8-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-00000.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-92147.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-92584.mp4']
sequences torch.Size([210, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93014.mp4']
sequences torch.Size([209, 1, 3, 384, 384])
predicting ['C3/15-2-6-submit-93060.mp4']
sequences torch.Size([208, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/19-1-3-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/19-2-3-submit-93060.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93014.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/3-1-6-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-00000.mp4']
sequences Video directory: ../dataset/C2/13-2-4-submit-82508.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93014.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82511.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-00000.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93060.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-73479.mp4 has 601 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83609.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92584.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83496.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92147.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82508.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93014.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C1/13-2-2-submit-73479.mp4 has 601 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83609.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92584.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-82511.mp4 has 723 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-00000.mp4 has 720 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-93060.mp4 has 726 frames which is more than 250 frames
Video directory: ../dataset/C2/13-2-4-submit-83496.mp4 has 721 frames which is more than 250 frames
Video directory: ../dataset/C3/13-2-5-submit-92147.mp4 has 720 frames which is more than 250 frames
torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93014.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/3-2-3-submit-93060.mp4']
sequences torch.Size([178, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93014.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-1-9-submit-93060.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-00000.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-92147.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-92584.mp4']
sequences torch.Size([120, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93014.mp4']
sequences torch.Size([119, 1, 3, 384, 384])
predicting ['C3/4-2-6-submit-93060.mp4']
sequences torch.Size([118, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-00000.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-92147.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-92584.mp4']
sequences torch.Size([150, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93014.mp4']
sequences torch.Size([149, 1, 3, 384, 384])
predicting ['C3/8-1-10-submit-93060.mp4']
sequences torch.Size([148, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-00000.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-92147.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-92584.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93014.mp4']
sequences torch.Size([180, 1, 3, 384, 384])
predicting ['C3/8-2-10-submit-93060.mp4']
sequences torch.Size([179, 1, 3, 384, 384])
predicted 120 labels for ['C3/8-2-10-submit-93060.mp4']
all_test_gt: [2.200000047683716, 2.0, 2.0, 3.0, 3.200000047683716, 3.0, 2.4000000953674316, 3.200000047683716, 3.200000047683716, 3.0, 2.5999999046325684, 3.0, 1.600000023841858, 3.5999999046325684, 2.799999952316284, 3.4000000953674316, 2.200000047683716, 4.199999809265137, 3.4000000953674316, 3.4000000953674316, 2.200000047683716, 3.5999999046325684, 3.5999999046325684, 3.799999952316284, 1.7999999523162842, 3.799999952316284, 3.4000000953674316, 3.4000000953674316, 1.7999999523162842, 2.799999952316284, 3.0, 3.200000047683716, 2.200000047683716, 3.0, 3.200000047683716, 2.200000047683716, 1.7999999523162842, 4.199999809265137, 2.5999999046325684, 3.5999999046325684, 1.600000023841858, 4.199999809265137, 2.799999952316284, 3.0, 1.399999976158142, 3.200000047683716, 2.0, 3.0, 1.600000023841858, 4.199999809265137, 2.5999999046325684, 2.4000000953674316, 2.200000047683716, 3.799999952316284, 3.4000000953674316, 3.0, 1.7999999523162842, 3.0, 3.200000047683716, 3.799999952316284, 3.799999952316284, 3.5999999046325684, 1.7999999523162842, 4.0, 4.0, 4.0, 4.0, 1.600000023841858, 4.199999809265137, 3.5999999046325684, 3.4000000953674316, 3.5999999046325684, 2.200000047683716, 3.200000047683716, 3.200000047683716, 3.4000000953674316, 3.5999999046325684, 1.7999999523162842, 3.799999952316284, 3.799999952316284, 3.200000047683716, 3.4000000953674316, 1.2000000476837158, 3.200000047683716, 3.4000000953674316, 3.4000000953674316, 3.5999999046325684, 2.0, 3.0, 4.0, 4.199999809265137, 3.4000000953674316, 2.0, 4.0, 4.0, 3.5999999046325684, 3.4000000953674316, 1.7999999523162842, 3.799999952316284, 4.199999809265137, 2.5999999046325684, 3.799999952316284, 1.600000023841858, 3.200000047683716, 3.799999952316284, 4.199999809265137, 3.799999952316284, 2.0, 3.799999952316284, 4.199999809265137, 3.4000000953674316, 3.4000000953674316, 1.7999999523162842, 3.5999999046325684, 4.199999809265137, 3.799999952316284, 3.4000000953674316, 1.7999999523162842, 4.199999809265137, 4.0]
saved 120 predictions to ./predictions/5usybm65/-1/Test3_preds.txt
scoring model
test_set1_score {'pearson_corr_coef': 0.8094302512377299, 'spearman_corr_coef': 0.7695873247605854, 'rmse': 0.4400420803893704}
test_set2_score {'pearson_corr_coef': 0.9118165813763178, 'spearman_corr_coef': 0.9027600215298596, 'rmse': 0.3873992122587816}
test_set3_score {'pearson_corr_coef': 0.8714714190052266, 'spearman_corr_coef': 0.8278081787038668, 'rmse': 0.422897279584585}
final_score 0.8488122961022645
